{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":14297133,"sourceType":"datasetVersion","datasetId":9126365},{"sourceId":14297740,"sourceType":"datasetVersion","datasetId":9126823}],"dockerImageVersionId":31234,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install sentence-transformers faiss-cpu chromadb","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-27T11:34:41.526226Z","iopub.execute_input":"2025-12-27T11:34:41.526649Z","iopub.status.idle":"2025-12-27T11:35:04.564686Z","shell.execute_reply.started":"2025-12-27T11:34:41.526618Z","shell.execute_reply":"2025-12-27T11:35:04.563743Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.12/dist-packages (5.1.1)\nCollecting faiss-cpu\n  Downloading faiss_cpu-1.13.2-cp310-abi3-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (7.6 kB)\nCollecting chromadb\n  Downloading chromadb-1.4.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.2 kB)\nRequirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.57.1)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.67.1)\nRequirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (2.8.0+cu126)\nRequirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.6.1)\nRequirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.15.3)\nRequirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (0.36.0)\nRequirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (11.3.0)\nRequirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.15.0)\nRequirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.12/dist-packages (from faiss-cpu) (2.0.2)\nRequirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from faiss-cpu) (25.0)\nRequirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.3.0)\nRequirement already satisfied: pydantic>=1.9 in /usr/local/lib/python3.12/dist-packages (from chromadb) (2.12.5)\nCollecting pybase64>=1.4.1 (from chromadb)\n  Downloading pybase64-1.4.3-cp312-cp312-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl.metadata (8.7 kB)\nRequirement already satisfied: uvicorn>=0.18.3 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.38.0)\nCollecting posthog<6.0.0,>=2.4.0 (from chromadb)\n  Downloading posthog-5.4.0-py3-none-any.whl.metadata (5.7 kB)\nCollecting onnxruntime>=1.14.1 (from chromadb)\n  Downloading onnxruntime-1.23.2-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (5.1 kB)\nRequirement already satisfied: opentelemetry-api>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.37.0)\nCollecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb)\n  Downloading opentelemetry_exporter_otlp_proto_grpc-1.39.1-py3-none-any.whl.metadata (2.5 kB)\nRequirement already satisfied: opentelemetry-sdk>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.37.0)\nRequirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.12/dist-packages (from chromadb) (0.22.1)\nCollecting pypika>=0.48.9 (from chromadb)\n  Downloading PyPika-0.48.9.tar.gz (67 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: overrides>=7.3.1 in /usr/local/lib/python3.12/dist-packages (from chromadb) (7.7.0)\nRequirement already satisfied: importlib-resources in /usr/local/lib/python3.12/dist-packages (from chromadb) (6.5.2)\nRequirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.75.1)\nCollecting bcrypt>=4.0.1 (from chromadb)\n  Downloading bcrypt-5.0.0-cp39-abi3-manylinux_2_34_x86_64.whl.metadata (10 kB)\nRequirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (0.20.0)\nRequirement already satisfied: kubernetes>=28.1.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (33.1.0)\nRequirement already satisfied: tenacity>=8.2.3 in /usr/local/lib/python3.12/dist-packages (from chromadb) (8.5.0)\nRequirement already satisfied: pyyaml>=6.0.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (6.0.3)\nCollecting mmh3>=4.0.1 (from chromadb)\n  Downloading mmh3-5.2.0-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (14 kB)\nRequirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.12/dist-packages (from chromadb) (3.11.3)\nRequirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (0.28.1)\nRequirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (14.2.0)\nRequirement already satisfied: jsonschema>=4.19.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (4.25.1)\nRequirement already satisfied: pyproject_hooks in /usr/local/lib/python3.12/dist-packages (from build>=1.0.3->chromadb) (1.2.0)\nRequirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.0->chromadb) (4.12.0)\nRequirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.0->chromadb) (2025.11.12)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.0->chromadb) (1.0.9)\nRequirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.0->chromadb) (3.11)\nRequirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.16.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.20.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.10.0)\nRequirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.5)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.2.1rc0)\nRequirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb) (25.4.0)\nRequirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb) (2025.9.1)\nRequirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb) (0.37.0)\nRequirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb) (0.27.1)\nRequirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (1.17.0)\nRequirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (2.9.0.post0)\nRequirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (2.38.0)\nRequirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (1.9.0)\nRequirement already satisfied: requests-oauthlib in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (2.0.0)\nRequirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (3.3.1)\nRequirement already satisfied: urllib3>=1.24.2 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (2.6.2)\nRequirement already satisfied: durationpy>=0.7 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (0.10)\nCollecting coloredlogs (from onnxruntime>=1.14.1->chromadb)\n  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\nRequirement already satisfied: flatbuffers in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb) (25.9.23)\nRequirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb) (5.29.5)\nRequirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb) (1.13.3)\nRequirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (8.7.0)\nRequirement already satisfied: googleapis-common-protos~=1.57 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.71.0)\nCollecting opentelemetry-exporter-otlp-proto-common==1.39.1 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n  Downloading opentelemetry_exporter_otlp_proto_common-1.39.1-py3-none-any.whl.metadata (1.8 kB)\nCollecting opentelemetry-proto==1.39.1 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n  Downloading opentelemetry_proto-1.39.1-py3-none-any.whl.metadata (2.3 kB)\nCollecting opentelemetry-sdk>=1.2.0 (from chromadb)\n  Downloading opentelemetry_sdk-1.39.1-py3-none-any.whl.metadata (1.5 kB)\nCollecting opentelemetry-api>=1.2.0 (from chromadb)\n  Downloading opentelemetry_api-1.39.1-py3-none-any.whl.metadata (1.5 kB)\nCollecting opentelemetry-semantic-conventions==0.60b1 (from opentelemetry-sdk>=1.2.0->chromadb)\n  Downloading opentelemetry_semantic_conventions-0.60b1-py3-none-any.whl.metadata (2.4 kB)\nCollecting backoff>=1.10.0 (from posthog<6.0.0,>=2.4.0->chromadb)\n  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\nRequirement already satisfied: distro>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from posthog<6.0.0,>=2.4.0->chromadb) (1.9.0)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=1.9->chromadb) (0.7.0)\nRequirement already satisfied: pydantic-core==2.41.5 in /usr/local/lib/python3.12/dist-packages (from pydantic>=1.9->chromadb) (2.41.5)\nRequirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=1.9->chromadb) (0.4.2)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->chromadb) (4.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->chromadb) (2.19.2)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (75.2.0)\nRequirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.80)\nRequirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (9.10.2.21)\nRequirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.4.1)\nRequirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (11.3.0.4)\nRequirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (10.3.7.77)\nRequirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (11.7.1.2)\nRequirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.5.4.2)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (0.7.1)\nRequirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (2.27.3)\nRequirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.85)\nRequirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (1.11.1.6)\nRequirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.4.0)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2025.11.3)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.6.2)\nRequirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer>=0.9.0->chromadb) (8.3.1)\nRequirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer>=0.9.0->chromadb) (1.5.4)\nCollecting httptools>=0.6.3 (from uvicorn[standard]>=0.18.3->chromadb)\n  Downloading httptools-0.7.1-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (3.5 kB)\nRequirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.1.1)\nCollecting uvloop>=0.15.1 (from uvicorn[standard]>=0.18.3->chromadb)\n  Downloading uvloop-0.22.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (4.9 kB)\nCollecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n  Downloading watchfiles-1.1.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\nRequirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (15.0.1)\nRequirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (1.5.3)\nRequirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\nRequirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.5.2)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.2)\nRequirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9.1)\nRequirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.23.0)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.4)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\nCollecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb)\n  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.3)\nRequirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.6.1)\nDownloading faiss_cpu-1.13.2-cp310-abi3-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (23.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.8/23.8 MB\u001b[0m \u001b[31m69.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading chromadb-1.4.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (21.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.7/21.7 MB\u001b[0m \u001b[31m70.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading bcrypt-5.0.0-cp39-abi3-manylinux_2_34_x86_64.whl (278 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.2/278.2 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading mmh3-5.2.0-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (103 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.3/103.3 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading onnxruntime-1.23.2-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (17.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.4/17.4 MB\u001b[0m \u001b[31m78.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading opentelemetry_exporter_otlp_proto_grpc-1.39.1-py3-none-any.whl (19 kB)\nDownloading opentelemetry_exporter_otlp_proto_common-1.39.1-py3-none-any.whl (18 kB)\nDownloading opentelemetry_proto-1.39.1-py3-none-any.whl (72 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.5/72.5 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading opentelemetry_sdk-1.39.1-py3-none-any.whl (132 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.6/132.6 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading opentelemetry_api-1.39.1-py3-none-any.whl (66 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.4/66.4 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading opentelemetry_semantic_conventions-0.60b1-py3-none-any.whl (219 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m220.0/220.0 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading posthog-5.4.0-py3-none-any.whl (105 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.4/105.4 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pybase64-1.4.3-cp312-cp312-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl (71 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.6/71.6 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading backoff-2.2.1-py3-none-any.whl (15 kB)\nDownloading httptools-0.7.1-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (517 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m517.7/517.7 kB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading uvloop-0.22.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (4.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m76.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading watchfiles-1.1.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (456 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m456.8/456.8 kB\u001b[0m \u001b[31m22.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: pypika\n  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for pypika: filename=pypika-0.48.9-py2.py3-none-any.whl size=53803 sha256=90aca2132654a70eeb791e07e2f5049f864944ccfcc1c7eb095a5f308b8af9cf\n  Stored in directory: /root/.cache/pip/wheels/d5/3d/69/8d68d249cd3de2584f226e27fd431d6344f7d70fd856ebd01b\nSuccessfully built pypika\nInstalling collected packages: pypika, uvloop, pybase64, opentelemetry-proto, mmh3, humanfriendly, httptools, faiss-cpu, bcrypt, backoff, watchfiles, posthog, opentelemetry-exporter-otlp-proto-common, opentelemetry-api, coloredlogs, opentelemetry-semantic-conventions, onnxruntime, opentelemetry-sdk, opentelemetry-exporter-otlp-proto-grpc, chromadb\n  Attempting uninstall: opentelemetry-proto\n    Found existing installation: opentelemetry-proto 1.37.0\n    Uninstalling opentelemetry-proto-1.37.0:\n      Successfully uninstalled opentelemetry-proto-1.37.0\n  Attempting uninstall: opentelemetry-exporter-otlp-proto-common\n    Found existing installation: opentelemetry-exporter-otlp-proto-common 1.37.0\n    Uninstalling opentelemetry-exporter-otlp-proto-common-1.37.0:\n      Successfully uninstalled opentelemetry-exporter-otlp-proto-common-1.37.0\n  Attempting uninstall: opentelemetry-api\n    Found existing installation: opentelemetry-api 1.37.0\n    Uninstalling opentelemetry-api-1.37.0:\n      Successfully uninstalled opentelemetry-api-1.37.0\n  Attempting uninstall: opentelemetry-semantic-conventions\n    Found existing installation: opentelemetry-semantic-conventions 0.58b0\n    Uninstalling opentelemetry-semantic-conventions-0.58b0:\n      Successfully uninstalled opentelemetry-semantic-conventions-0.58b0\n  Attempting uninstall: opentelemetry-sdk\n    Found existing installation: opentelemetry-sdk 1.37.0\n    Uninstalling opentelemetry-sdk-1.37.0:\n      Successfully uninstalled opentelemetry-sdk-1.37.0\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nopentelemetry-exporter-otlp-proto-http 1.37.0 requires opentelemetry-exporter-otlp-proto-common==1.37.0, but you have opentelemetry-exporter-otlp-proto-common 1.39.1 which is incompatible.\nopentelemetry-exporter-otlp-proto-http 1.37.0 requires opentelemetry-proto==1.37.0, but you have opentelemetry-proto 1.39.1 which is incompatible.\nopentelemetry-exporter-otlp-proto-http 1.37.0 requires opentelemetry-sdk~=1.37.0, but you have opentelemetry-sdk 1.39.1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed backoff-2.2.1 bcrypt-5.0.0 chromadb-1.4.0 coloredlogs-15.0.1 faiss-cpu-1.13.2 httptools-0.7.1 humanfriendly-10.0 mmh3-5.2.0 onnxruntime-1.23.2 opentelemetry-api-1.39.1 opentelemetry-exporter-otlp-proto-common-1.39.1 opentelemetry-exporter-otlp-proto-grpc-1.39.1 opentelemetry-proto-1.39.1 opentelemetry-sdk-1.39.1 opentelemetry-semantic-conventions-0.60b1 posthog-5.4.0 pybase64-1.4.3 pypika-0.48.9 uvloop-0.22.1 watchfiles-1.1.1\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"!pip install langchain langchain-community pymupdf docx2txt","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-27T11:35:04.566578Z","iopub.execute_input":"2025-12-27T11:35:04.567236Z","iopub.status.idle":"2025-12-27T11:35:17.337925Z","shell.execute_reply.started":"2025-12-27T11:35:04.567203Z","shell.execute_reply":"2025-12-27T11:35:17.336718Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: langchain in /usr/local/lib/python3.12/dist-packages (0.3.27)\nCollecting langchain-community\n  Downloading langchain_community-0.4.1-py3-none-any.whl.metadata (3.0 kB)\nCollecting pymupdf\n  Downloading pymupdf-1.26.7-cp310-abi3-manylinux_2_28_x86_64.whl.metadata (3.4 kB)\nCollecting docx2txt\n  Downloading docx2txt-0.9-py3-none-any.whl.metadata (529 bytes)\nRequirement already satisfied: langchain-core<1.0.0,>=0.3.72 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.3.79)\nRequirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.3.11)\nRequirement already satisfied: langsmith>=0.1.17 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.4.37)\nRequirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.12.5)\nCollecting SQLAlchemy<3,>=1.4 (from langchain)\n  Downloading sqlalchemy-2.0.45-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (9.5 kB)\nRequirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.32.5)\nRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.12/dist-packages (from langchain) (6.0.3)\nINFO: pip is looking at multiple versions of langchain-community to determine which version is compatible with other requirements. This could take a while.\nCollecting langchain-community\n  Downloading langchain_community-0.4-py3-none-any.whl.metadata (3.0 kB)\n  Downloading langchain_community-0.3.31-py3-none-any.whl.metadata (3.0 kB)\nRequirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (3.13.2)\nRequirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (8.5.0)\nRequirement already satisfied: dataclasses-json<0.7.0,>=0.6.7 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.6.7)\nRequirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.11.0)\nRequirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.4.3)\nRequirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.0.2)\nRequirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\nRequirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.4.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.8.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.7.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.4.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.22.0)\nRequirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community) (3.26.1)\nRequirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community) (0.9.0)\nRequirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (1.33)\nRequirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (4.15.0)\nRequirement already satisfied: packaging<26.0.0,>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (25.0)\nRequirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (0.28.1)\nRequirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (3.11.3)\nRequirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (1.0.0)\nRequirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (0.25.0)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\nRequirement already satisfied: pydantic-core==2.41.5 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.41.5)\nRequirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.2)\nRequirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community) (1.1.1)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (3.4.4)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (3.11)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (2.6.2)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (2025.11.12)\nRequirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.4)\nRequirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (4.12.0)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.0.9)\nRequirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (0.16.0)\nRequirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<1.0.0,>=0.3.72->langchain) (3.0.0)\nRequirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain-community) (1.1.0)\nDownloading langchain_community-0.3.31-py3-none-any.whl (2.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m26.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading pymupdf-1.26.7-cp310-abi3-manylinux_2_28_x86_64.whl (24.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.1/24.1 MB\u001b[0m \u001b[31m80.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading docx2txt-0.9-py3-none-any.whl (4.0 kB)\nDownloading sqlalchemy-2.0.45-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (3.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m71.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: docx2txt, SQLAlchemy, pymupdf, langchain-community\n  Attempting uninstall: SQLAlchemy\n    Found existing installation: SQLAlchemy 1.2.19\n    Uninstalling SQLAlchemy-1.2.19:\n      Successfully uninstalled SQLAlchemy-1.2.19\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nxmanager 0.7.1 requires sqlalchemy==1.2.19, but you have sqlalchemy 2.0.45 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed SQLAlchemy-2.0.45 docx2txt-0.9 langchain-community-0.3.31 pymupdf-1.26.7\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"from langchain_community.document_loaders import DirectoryLoader","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-27T11:35:17.339528Z","iopub.execute_input":"2025-12-27T11:35:17.339830Z","iopub.status.idle":"2025-12-27T11:35:19.187948Z","shell.execute_reply.started":"2025-12-27T11:35:17.339799Z","shell.execute_reply":"2025-12-27T11:35:19.186795Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"from langchain_community.document_loaders import PyPDFLoader, PyMuPDFLoader","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-27T11:35:19.190739Z","iopub.execute_input":"2025-12-27T11:35:19.191035Z","iopub.status.idle":"2025-12-27T11:35:28.660974Z","shell.execute_reply.started":"2025-12-27T11:35:19.191011Z","shell.execute_reply":"2025-12-27T11:35:28.659761Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"dir_loader = DirectoryLoader(\n    \"/kaggle/input\",\n    glob=\"**/*.pdf\",\n    loader_cls=PyMuPDFLoader,\n    show_progress=False\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-27T11:35:28.662245Z","iopub.execute_input":"2025-12-27T11:35:28.662847Z","iopub.status.idle":"2025-12-27T11:35:28.668636Z","shell.execute_reply.started":"2025-12-27T11:35:28.662814Z","shell.execute_reply":"2025-12-27T11:35:28.667626Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"chunks = dir_loader.load()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-27T11:35:28.670077Z","iopub.execute_input":"2025-12-27T11:35:28.670479Z","iopub.status.idle":"2025-12-27T11:35:35.277461Z","shell.execute_reply.started":"2025-12-27T11:35:28.670448Z","shell.execute_reply":"2025-12-27T11:35:35.276351Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"import numpy as np\nfrom sentence_transformers import SentenceTransformer\nimport chromadb\nfrom chromadb.config import Settings\nimport uuid\nfrom sklearn.metrics.pairwise import cosine_similarity\nfrom typing import List,Any, Dict\nimport os","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-27T11:35:35.278719Z","iopub.execute_input":"2025-12-27T11:35:35.279131Z","iopub.status.idle":"2025-12-27T11:36:14.961230Z","shell.execute_reply.started":"2025-12-27T11:35:35.279097Z","shell.execute_reply":"2025-12-27T11:36:14.960175Z"}},"outputs":[{"name":"stderr","text":"2025-12-27 11:35:45.435846: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1766835345.727538      55 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1766835345.807960      55 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nW0000 00:00:1766835346.542514      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1766835346.542570      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1766835346.542573      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1766835346.542576      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"class EmbeddingManager:\n\n    def __init__(self,model_name='all-MiniLM-L6-v2'):\n        self.model_name = model_name\n        self.model = None\n        self._load_model()\n\n    def _load_model(self):\n        try:\n            print(f\"Embedding Model Name: {self.model_name}\")\n            self.model = SentenceTransformer(self.model_name)\n            print(\"Model Loaded Succesfully\")\n            print(f\"Embedding Dim: {self.model.get_sentence_embedding_dimension()}\")\n        except Exception as e:\n            print(\"Error in loading model\")\n            raise\n\n    def generate_embeddings(self, texts:List[str]) -> np.ndarray:\n        if not self.model:\n            raise ValueError(\"Model Not Loaded\")\n\n        print(f\"Generating embeddings for texts of len: {len(texts)}\")\n        embeddings = self.model.encode(texts,show_progress_bar=True)\n        print(f\"Generated embeddings of shape: {embeddings.shape}\")\n        return embeddings\n\n\n\n\n    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-27T11:36:14.962310Z","iopub.execute_input":"2025-12-27T11:36:14.962620Z","iopub.status.idle":"2025-12-27T11:36:14.971311Z","shell.execute_reply.started":"2025-12-27T11:36:14.962572Z","shell.execute_reply":"2025-12-27T11:36:14.969619Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"embedding_manager = EmbeddingManager()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-27T11:36:14.972956Z","iopub.execute_input":"2025-12-27T11:36:14.973263Z","iopub.status.idle":"2025-12-27T11:36:17.748994Z","shell.execute_reply.started":"2025-12-27T11:36:14.973236Z","shell.execute_reply":"2025-12-27T11:36:17.747919Z"}},"outputs":[{"name":"stdout","text":"Embedding Model Name: all-MiniLM-L6-v2\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5656ad89930a4bbbbe04f5756fa89a63"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b08bd531ee194a1c896e4ef57ed0ec07"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"81bbebf6e2814e7695a7f483f82e582e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c0d358bfc55b4a06bda5b39abac17c68"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"773b4cf59a114ef990c4d873f9bce4a4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cc7bf2e31a0d4d39a0be8ddb2aabb92d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8777864de1454e83bfb100469b143768"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"806558a4c9554724945ef78142c61a05"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6e640c771d8b478195f9a48983faa236"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a5658fb30eb34bc5b863d832bf176709"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5ade5da1ec874582a0e3e3658965f94f"}},"metadata":{}},{"name":"stdout","text":"Model Loaded Succesfully\nEmbedding Dim: 384\n","output_type":"stream"}],"execution_count":11},{"cell_type":"markdown","source":"### Vector Store","metadata":{}},{"cell_type":"code","source":"class VectorStore:\n\n    def __init__(self,collection_name:str=\"pdf_docs\",persist_directory:str=\"/kaggle/working/\"):\n        self.collection_name=collection_name\n        self.persist_directory = persist_directory\n        self.client = None\n        self.collection=None\n        self._initialise_store()\n\n    def _initialise_store(self):\n\n        try:\n            #create persist chromadb client\n            os.makedirs(self.persist_directory,exist_ok=True)\n            self.client = chromadb.PersistentClient(path=self.persist_directory)\n    \n            #get or create collection\n            self.collection = self.client.get_or_create_collection(\n                name=self.collection_name,\n                metadata={\"Description\":\"PDF Doc emmbedings for RAG\"}\n            )\n    \n            print(f\"VectorStore is created with name: {self.collection_name}\")\n            print(f\"Existing documents in collection: {self.collection.count()}\")\n\n        except Exception as e:\n            print(f\"Error at initialising vector store {e}\")\n            raise\n\n    def add_documents(self, documents: List[Any], embeddings=np.ndarray):\n        if len(documents) != len(embeddings):\n            raise ValueError(\"Number of documents doesn't match embeddings\")\n\n        print(f\"Adding {len(documents)} to vector store\")\n\n        #Data for chromadb\n        ids = []\n        metadatas = []\n        document_text = []\n        embedding_list = []\n\n        for i,(doc,emb) in enumerate(zip(documents,embeddings)):\n\n            #generating ids\n            doc_id = f\"doc_{uuid.uuid4().hex[:8]}_{i}\"\n            ids.append(doc_id)\n        \n            #preparing metadata\n            metadata = dict()\n            metadata['doc_index'] = i\n            metadata['content_length'] = len(doc.page_content)\n            metadatas.append(metadata)\n\n            document_text.append(doc.page_content)\n\n            embedding_list.append(emb.tolist())\n\n        try:\n            self.collection.add(\n                ids = ids,\n                embeddings = embedding_list,\n                metadatas = metadatas,\n                documents = document_text\n            )\n\n            print(f\"successfully added { len(documents)} documents to vector store\") \n            print(f\"Number of documents in collection {self.collection.count()}\")\n        except Exception as e:\n            print(f\"Error in adding documents to collection {e}\")\n            raise","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-27T11:36:17.752750Z","iopub.execute_input":"2025-12-27T11:36:17.753091Z","iopub.status.idle":"2025-12-27T11:36:17.765377Z","shell.execute_reply.started":"2025-12-27T11:36:17.753058Z","shell.execute_reply":"2025-12-27T11:36:17.763964Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"vector_store = VectorStore()\nvector_store","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-27T11:36:17.766711Z","iopub.execute_input":"2025-12-27T11:36:17.767103Z","iopub.status.idle":"2025-12-27T11:36:18.275237Z","shell.execute_reply.started":"2025-12-27T11:36:17.767053Z","shell.execute_reply":"2025-12-27T11:36:18.273984Z"}},"outputs":[{"name":"stdout","text":"VectorStore is created with name: pdf_docs\nExisting documents in collection: 0\n","output_type":"stream"},{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"<__main__.VectorStore at 0x7f6966cdfe30>"},"metadata":{}}],"execution_count":13},{"cell_type":"code","source":"texts = [doc.page_content for doc in chunks]\n\nembeddings = embedding_manager.generate_embeddings(texts)\n\nvector_store.add_documents(chunks,embeddings)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-27T11:36:18.276359Z","iopub.execute_input":"2025-12-27T11:36:18.276687Z","iopub.status.idle":"2025-12-27T11:37:33.377094Z","shell.execute_reply.started":"2025-12-27T11:36:18.276634Z","shell.execute_reply":"2025-12-27T11:37:33.375222Z"}},"outputs":[{"name":"stdout","text":"Generating embeddings for texts of len: 1098\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/35 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4cf901afec3a4566b059449b78f7b30a"}},"metadata":{}},{"name":"stdout","text":"Generated embeddings of shape: (1098, 384)\nAdding 1098 to vector store\nsuccessfully added 1098 documents to vector store\nNumber of documents in collection 1098\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"class RAGRetriever:\n\n    def __init__(self,vector_store:VectorStore, embedding_manager:EmbeddingManager):\n        self.vector_store = vector_store\n        self.embedding_manager = embedding_manager\n\n    def retrieve(self, query:str, top_k : int=5, score_threshold:float=0.0) -> List[Dict[str,Any]]:\n        print(\"retrieving documents for query: \", query)\n\n        query_embedding = self.embedding_manager.generate_embeddings([query])[0]\n\n        try:\n            res = self.vector_store.collection.query(\n                query_embeddings = [query_embedding.tolist()],\n                n_results = top_k\n            )\n\n            retrieved_docs = []\n\n            if res['documents'] and res['documents'][0]:\n                documents = res['documents'][0]\n                metadatas = res['metadatas'][0]\n                distances = res['distances'][0]\n                ids = res['ids'][0]\n\n                for i,(document,metadata,distance,doc_id) in enumerate(zip(documents,metadatas,distances,ids)):\n                    similarity_score = 1-distance\n    \n                    if similarity_score>score_threshold:\n                        retrieved_docs.append({\n                            'id':doc_id,\n                            'content':document,\n                            'metadata':metadata,\n                            'similarity_score':similarity_score,\n                            'distance':distance,\n                            'rank':i+1\n                        })\n    \n                print(f\"Retrieved {len(retrieved_docs)} document after filtering \")\n            else:\n                print(\"No documents retrieved\")\n\n            return retrieved_docs\n        except Exception as e:\n            print(\"Error while retrieving\")\n            raise\n            \n            ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-27T11:37:33.378596Z","iopub.execute_input":"2025-12-27T11:37:33.379195Z","iopub.status.idle":"2025-12-27T11:37:33.391045Z","shell.execute_reply.started":"2025-12-27T11:37:33.379145Z","shell.execute_reply":"2025-12-27T11:37:33.389248Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"rag_retriever = RAGRetriever(vector_store,embedding_manager)\nrag_retriever","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-27T11:37:33.393984Z","iopub.execute_input":"2025-12-27T11:37:33.394376Z","iopub.status.idle":"2025-12-27T11:37:33.430825Z","shell.execute_reply.started":"2025-12-27T11:37:33.394344Z","shell.execute_reply":"2025-12-27T11:37:33.429642Z"}},"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"<__main__.RAGRetriever at 0x7f6966c2e810>"},"metadata":{}}],"execution_count":16},{"cell_type":"code","source":"rag_retriever.retrieve(\"What is probability\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-27T11:37:33.432197Z","iopub.execute_input":"2025-12-27T11:37:33.432530Z","iopub.status.idle":"2025-12-27T11:37:33.506136Z","shell.execute_reply.started":"2025-12-27T11:37:33.432499Z","shell.execute_reply":"2025-12-27T11:37:33.504042Z"}},"outputs":[{"name":"stdout","text":"retrieving documents for query:  What is probability\nGenerating embeddings for texts of len: 1\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"717932223db042628b5d279db62cb384"}},"metadata":{}},{"name":"stdout","text":"Generated embeddings of shape: (1, 384)\nRetrieved 1 document after filtering \n","output_type":"stream"},{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"[{'id': 'doc_920d0237_57',\n  'content': '2\\nProbability\\n2.1\\nIntroduction\\nProbability theory is nothing but common sense reduced to calculation. — Pierre Laplace,\\n1812\\nIn the previous chapter, we saw how probability can play a useful role in machine learning. In\\nthis chapter, we discuss probability theory in more detail. We do not have to space to go into\\ngreat detail — for that, you are better off consulting some of the excellent textbooks available\\non this topic, such as (Jaynes 2003; Bertsekas and Tsitsiklis 2008; Wasserman 2004). But we will\\nbrieﬂy review many of the key ideas you will need in later chapters.\\nBefore we start with the more technical material, let us pause and ask: what is probability?\\nWe are all familiar with the phrase “the probability that a coin will land heads is 0.5”. But what\\ndoes this mean? There are actually at least two different interpretations of probability. One is\\ncalled the frequentist interpretation. In this view, probabilities represent long run frequencies\\nof events. For example, the above statement means that, if we ﬂip the coin many times, we\\nexpect it to land heads about half the time.1\\nThe other interpretation is called the Bayesian interpretation of probability. In this view,\\nprobability is used to quantify our uncertainty about something; hence it is fundamentally\\nrelated to information rather than repeated trials (Jaynes 2003). In the Bayesian view, the above\\nstatement means we believe the coin is equally likely to land heads or tails on the next toss.\\nOne big advantage of the Bayesian interpretation is that it can be used to model our uncer-\\ntainty about events that do not have long term frequencies. For example, we might want to\\ncompute the probability that the polar ice cap will melt by 2020 CE. This event will happen zero\\nor one times, but cannot happen repeatedly. Nevertheless, we ought to be able to quantify our\\nuncertainty about this event; based on how probable we think this event is, we will (hopefully!)\\ntake appropriate actions (see Section 5.7 for a discussion of optimal decision making under\\nuncertainty). To give some more machine learning oriented examples, we might have received\\na speciﬁc email message, and want to compute the probability it is spam. Or we might have\\nobserved a “blip” on our radar screen, and want to compute the probability distribution over\\nthe location of the corresponding target (be it a bird, plane, or missile). In all these cases, the\\nidea of repeated trials does not make sense, but the Bayesian interpretation is valid and indeed\\n1. Actually, the Stanford statistician (and former professional magician) Persi Diaconis has shown that a coin is about\\n51% likely to land facing the same way up as it started, due to the physics of the problem (Diaconis et al. 2007).',\n  'metadata': {'doc_index': 57, 'content_length': 2745},\n  'similarity_score': 0.32040315866470337,\n  'distance': 0.6795968413352966,\n  'rank': 1}]"},"metadata":{}}],"execution_count":17},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Integration with LLM ","metadata":{}},{"cell_type":"code","source":"!pip install -U --no-cache-dir \\\n  langchain==0.2.16 \\\n  langchain-core==0.2.38 \\\n  langchain-openai==0.1.23\n!pip install transformers","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-27T11:37:33.508002Z","iopub.execute_input":"2025-12-27T11:37:33.508394Z","iopub.status.idle":"2025-12-27T11:37:55.319836Z","shell.execute_reply.started":"2025-12-27T11:37:33.508360Z","shell.execute_reply":"2025-12-27T11:37:55.318690Z"}},"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Collecting langchain==0.2.16\n  Downloading langchain-0.2.16-py3-none-any.whl.metadata (7.1 kB)\nCollecting langchain-core==0.2.38\n  Downloading langchain_core-0.2.38-py3-none-any.whl.metadata (6.2 kB)\nCollecting langchain-openai==0.1.23\n  Downloading langchain_openai-0.1.23-py3-none-any.whl.metadata (2.6 kB)\nRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.12/dist-packages (from langchain==0.2.16) (6.0.3)\nRequirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.12/dist-packages (from langchain==0.2.16) (2.0.45)\nRequirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.12/dist-packages (from langchain==0.2.16) (3.13.2)\nCollecting langchain-text-splitters<0.3.0,>=0.2.0 (from langchain==0.2.16)\n  Downloading langchain_text_splitters-0.2.4-py3-none-any.whl.metadata (2.3 kB)\nCollecting langsmith<0.2.0,>=0.1.17 (from langchain==0.2.16)\n  Downloading langsmith-0.1.147-py3-none-any.whl.metadata (14 kB)\nCollecting numpy<2.0.0,>=1.26.0 (from langchain==0.2.16)\n  Downloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.12/dist-packages (from langchain==0.2.16) (2.12.5)\nRequirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.12/dist-packages (from langchain==0.2.16) (2.32.5)\nRequirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain==0.2.16) (8.5.0)\nRequirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.12/dist-packages (from langchain-core==0.2.38) (1.33)\nCollecting packaging<25,>=23.2 (from langchain-core==0.2.38)\n  Downloading packaging-24.2-py3-none-any.whl.metadata (3.2 kB)\nRequirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.12/dist-packages (from langchain-core==0.2.38) (4.15.0)\nRequirement already satisfied: openai<2.0.0,>=1.40.0 in /usr/local/lib/python3.12/dist-packages (from langchain-openai==0.1.23) (1.109.1)\nRequirement already satisfied: tiktoken<1,>=0.7 in /usr/local/lib/python3.12/dist-packages (from langchain-openai==0.1.23) (0.12.0)\nRequirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.2.16) (2.6.1)\nRequirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.2.16) (1.4.0)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.2.16) (25.4.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.2.16) (1.8.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.2.16) (6.7.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.2.16) (0.4.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.2.16) (1.22.0)\nRequirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core==0.2.38) (3.0.0)\nRequirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain==0.2.16) (0.28.1)\nRequirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain==0.2.16) (3.11.3)\nRequirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain==0.2.16) (1.0.0)\nRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.40.0->langchain-openai==0.1.23) (4.12.0)\nRequirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.40.0->langchain-openai==0.1.23) (1.9.0)\nRequirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.40.0->langchain-openai==0.1.23) (0.11.1)\nRequirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.40.0->langchain-openai==0.1.23) (1.3.1)\nRequirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.40.0->langchain-openai==0.1.23) (4.67.1)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1->langchain==0.2.16) (0.7.0)\nRequirement already satisfied: pydantic-core==2.41.5 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1->langchain==0.2.16) (2.41.5)\nRequirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1->langchain==0.2.16) (0.4.2)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain==0.2.16) (3.4.4)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain==0.2.16) (3.11)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain==0.2.16) (2.6.2)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain==0.2.16) (2025.11.12)\nRequirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3,>=1.4->langchain==0.2.16) (3.2.4)\nRequirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken<1,>=0.7->langchain-openai==0.1.23) (2025.11.3)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain==0.2.16) (1.0.9)\nRequirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain==0.2.16) (0.16.0)\nDownloading langchain-0.2.16-py3-none-any.whl (1.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m26.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading langchain_core-0.2.38-py3-none-any.whl (396 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m396.4/396.4 kB\u001b[0m \u001b[31m274.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading langchain_openai-0.1.23-py3-none-any.whl (51 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.0/52.0 kB\u001b[0m \u001b[31m156.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading langchain_text_splitters-0.2.4-py3-none-any.whl (25 kB)\nDownloading langsmith-0.1.147-py3-none-any.whl (311 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.8/311.8 kB\u001b[0m \u001b[31m263.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.0/18.0 MB\u001b[0m \u001b[31m256.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading packaging-24.2-py3-none-any.whl (65 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.5/65.5 kB\u001b[0m \u001b[31m256.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: packaging, numpy, langsmith, langchain-core, langchain-text-splitters, langchain-openai, langchain\n  Attempting uninstall: packaging\n    Found existing installation: packaging 25.0\n    Uninstalling packaging-25.0:\n      Successfully uninstalled packaging-25.0\n  Attempting uninstall: numpy\n    Found existing installation: numpy 2.0.2\n    Uninstalling numpy-2.0.2:\n      Successfully uninstalled numpy-2.0.2\n  Attempting uninstall: langsmith\n    Found existing installation: langsmith 0.4.37\n    Uninstalling langsmith-0.4.37:\n      Successfully uninstalled langsmith-0.4.37\n  Attempting uninstall: langchain-core\n    Found existing installation: langchain-core 0.3.79\n    Uninstalling langchain-core-0.3.79:\n      Successfully uninstalled langchain-core-0.3.79\n  Attempting uninstall: langchain-text-splitters\n    Found existing installation: langchain-text-splitters 0.3.11\n    Uninstalling langchain-text-splitters-0.3.11:\n      Successfully uninstalled langchain-text-splitters-0.3.11\n  Attempting uninstall: langchain\n    Found existing installation: langchain 0.3.27\n    Uninstalling langchain-0.3.27:\n      Successfully uninstalled langchain-0.3.27\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbigframes 2.26.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\nlangchain-community 0.3.31 requires langchain<2.0.0,>=0.3.27, but you have langchain 0.2.16 which is incompatible.\nlangchain-community 0.3.31 requires langchain-core<2.0.0,>=0.3.78, but you have langchain-core 0.2.38 which is incompatible.\nray 2.52.1 requires click!=8.3.*,>=7.0, but you have click 8.3.1 which is incompatible.\ncesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\ngoogle-colab 1.0.0 requires jupyter-server==2.14.0, but you have jupyter-server 2.12.5 which is incompatible.\ngoogle-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\ndopamine-rl 4.1.2 requires gymnasium>=1.0.0, but you have gymnasium 0.29.0 which is incompatible.\njaxlib 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\nthinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\nopencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\nopencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\njax 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\ncudf-cu12 25.6.0 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 22.0.0 which is incompatible.\ngradio 5.49.1 requires pydantic<2.12,>=2.0, but you have pydantic 2.12.5 which is incompatible.\nbigframes 2.26.0 requires rich<14,>=12.4.4, but you have rich 14.2.0 which is incompatible.\nopencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\npytensor 2.35.1 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\npylibcudf-cu12 25.6.0 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 22.0.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed langchain-0.2.16 langchain-core-0.2.38 langchain-openai-0.1.23 langchain-text-splitters-0.2.4 langsmith-0.1.147 numpy-1.26.4 packaging-24.2\n","output_type":"stream"},{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.1)\nRequirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.36.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (24.2)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2025.11.3)\nRequirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.5)\nRequirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.6.2)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.10.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.2.1rc0)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.4)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.11)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.6.2)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.11.12)\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"from transformers import AutoModelForCausalLM, AutoTokenizer\nimport os","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-27T11:37:55.321582Z","iopub.execute_input":"2025-12-27T11:37:55.322084Z","iopub.status.idle":"2025-12-27T11:37:55.328062Z","shell.execute_reply.started":"2025-12-27T11:37:55.322027Z","shell.execute_reply":"2025-12-27T11:37:55.327073Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"model_path = \"/kaggle/input/gemma/transformers/2b-it/3\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-27T11:37:55.329650Z","iopub.execute_input":"2025-12-27T11:37:55.330027Z","iopub.status.idle":"2025-12-27T11:37:55.355873Z","shell.execute_reply.started":"2025-12-27T11:37:55.329995Z","shell.execute_reply":"2025-12-27T11:37:55.354336Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(model_path)\nmodel = AutoModelForCausalLM.from_pretrained(\n    model_path,\n    device_map=\"auto\"\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-27T11:37:55.357646Z","iopub.execute_input":"2025-12-27T11:37:55.358042Z","iopub.status.idle":"2025-12-27T11:38:17.386912Z","shell.execute_reply.started":"2025-12-27T11:37:55.357993Z","shell.execute_reply":"2025-12-27T11:38:17.385596Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9c08866143174b19961e051a5965da0b"}},"metadata":{}}],"execution_count":21},{"cell_type":"code","source":"from transformers import pipeline\nfrom langchain.llms import HuggingFacePipeline","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-27T11:38:17.388187Z","iopub.execute_input":"2025-12-27T11:38:17.388529Z","iopub.status.idle":"2025-12-27T11:38:17.840278Z","shell.execute_reply.started":"2025-12-27T11:38:17.388483Z","shell.execute_reply":"2025-12-27T11:38:17.838491Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"pipe = pipeline(\n    \"text-generation\",\n    model=model,\n    tokenizer=tokenizer,\n    max_new_tokens=512,\n    temperature=0.2,\n    do_sample=True,\n    return_full_text=False \n)\n\nllm = HuggingFacePipeline(pipeline=pipe)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-27T11:38:17.841903Z","iopub.execute_input":"2025-12-27T11:38:17.842322Z","iopub.status.idle":"2025-12-27T11:38:17.853240Z","shell.execute_reply.started":"2025-12-27T11:38:17.842285Z","shell.execute_reply":"2025-12-27T11:38:17.851504Z"}},"outputs":[{"name":"stderr","text":"Device set to use cpu\n/tmp/ipykernel_55/1595155424.py:11: LangChainDeprecationWarning: The class `HuggingFacePipeline` was deprecated in LangChain 0.0.37 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFacePipeline``.\n  llm = HuggingFacePipeline(pipeline=pipe)\n","output_type":"stream"}],"execution_count":23},{"cell_type":"code","source":"def rag_simple(query,retriever, llm, top_k=3):\n    res = retriever.retrieve(query,top_k=top_k)\n    context = \"\\n\\n\".join([doc['content'] for doc in res]) if res else \"\"\n\n    if not context:\n        return \"No relevant context\"\n\n    prompt = f\"\"\"Use the following context to answer the question consisely\n            Context:\n            {context}\n            Question:\n            {query}\n            \n            Answer:\"\"\"\n\n    response = llm.invoke([prompt])\n    return response","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-27T11:38:17.854921Z","iopub.execute_input":"2025-12-27T11:38:17.855348Z","iopub.status.idle":"2025-12-27T11:38:17.880376Z","shell.execute_reply.started":"2025-12-27T11:38:17.855287Z","shell.execute_reply":"2025-12-27T11:38:17.879209Z"}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"answer = rag_simple(\n    query=\"what is Maximum entropy derivation of the Gaussian\",\n    retriever=rag_retriever,\n    llm=llm\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-27T11:38:17.881941Z","iopub.execute_input":"2025-12-27T11:38:17.882255Z","iopub.status.idle":"2025-12-27T11:40:38.361728Z","shell.execute_reply.started":"2025-12-27T11:38:17.882220Z","shell.execute_reply":"2025-12-27T11:40:38.359410Z"}},"outputs":[{"name":"stdout","text":"retrieving documents for query:  what is Maximum entropy derivation of the Gaussian\nGenerating embeddings for texts of len: 1\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"721f6927c39a4ea6948fe82591599524"}},"metadata":{}},{"name":"stdout","text":"Generated embeddings of shape: (1, 384)\nRetrieved 3 document after filtering \n","output_type":"stream"}],"execution_count":25},{"cell_type":"code","source":"answer","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-27T11:40:38.364394Z","iopub.execute_input":"2025-12-27T11:40:38.365039Z","iopub.status.idle":"2025-12-27T11:40:38.374997Z","shell.execute_reply.started":"2025-12-27T11:40:38.364996Z","shell.execute_reply":"2025-12-27T11:40:38.373654Z"}},"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"'\\n            The Maximum entropy derivation of the Gaussian is given by\\n            h(N(μ, Σ)) = 1\\n2 ln\\n\\x14\\n(2πe)D|Σ|'"},"metadata":{}}],"execution_count":26},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def rag_advanced(query,retriever, llm, top_k=3,min_score=0.2,return_context=False):\n    res = retriever.retrieve(query,top_k=top_k)\n    if not res:\n        return {'answer':\"No relevant context\",\"sources\":[],\"confidence_score\":0.0,\"context\":''}\n\n    context = \"\\n\\n\".join([doc['content'] for doc in res]) if res else \"\"\n\n    sources = [{\n        \"source\":doc['metadata'].get('source_file',doc['metadata'].get('source','unknown')),\n        'page':doc['metadata'].get('page','unknown'),\n        'score':doc['similarity_score'],\n        'preview':doc['content'][:300]+\"...\",\n    } for doc in res]\n\n    confidence = max(doc['similarity_score'] for doc in res)\n    prompt = f\"\"\"Use the following context to answer the question consisely: \\nContext: \\n {context}\n            Question: \\n{query}\n            Answer:\"\"\"\n\n    response = llm.invoke([prompt])\n\n    output = {\n        'answer':response,\n        'sources':sources,\n        'confidence':confidence\n    }\n    return output","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-27T11:40:38.376975Z","iopub.execute_input":"2025-12-27T11:40:38.377445Z","iopub.status.idle":"2025-12-27T11:40:38.399666Z","shell.execute_reply.started":"2025-12-27T11:40:38.377400Z","shell.execute_reply":"2025-12-27T11:40:38.398437Z"}},"outputs":[],"execution_count":27},{"cell_type":"code","source":"answer = rag_advanced(\n    query=\"explain the use of linear regression\",\n    retriever=rag_retriever,\n    llm=llm\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"answer['answer']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-27T11:40:43.327827Z","iopub.status.idle":"2025-12-27T11:40:43.328180Z","shell.execute_reply.started":"2025-12-27T11:40:43.328022Z","shell.execute_reply":"2025-12-27T11:40:43.328047Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"answer['sources']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-27T11:40:43.331064Z","iopub.status.idle":"2025-12-27T11:40:43.331629Z","shell.execute_reply.started":"2025-12-27T11:40:43.331337Z","shell.execute_reply":"2025-12-27T11:40:43.331375Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install typesense","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-27T11:40:43.333380Z","iopub.status.idle":"2025-12-27T11:40:43.333846Z","shell.execute_reply.started":"2025-12-27T11:40:43.333589Z","shell.execute_reply":"2025-12-27T11:40:43.333650Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import typesense","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-27T11:40:43.335505Z","iopub.status.idle":"2025-12-27T11:40:43.336389Z","shell.execute_reply.started":"2025-12-27T11:40:43.336199Z","shell.execute_reply":"2025-12-27T11:40:43.336227Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"client = typesense.Client({\n    'nodes': [{\n        'host': 'kpuysm2df54h67x9p-1.a1.typesense.net', \n        'port': '443',\n        'protocol': 'https'\n        }],\n    'api_key': 'yoyaOpBaoCX65ZgeryXnCOZRJNAqCjBZ',\n    'connection_timeout_seconds': 2\n})","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-27T11:48:00.512487Z","iopub.execute_input":"2025-12-27T11:48:00.512911Z","iopub.status.idle":"2025-12-27T11:48:00.522172Z","shell.execute_reply.started":"2025-12-27T11:48:00.512865Z","shell.execute_reply":"2025-12-27T11:48:00.520964Z"}},"outputs":[{"name":"stderr","text":"WARNING:typesense:Deprecation warning: AnalyticsRulesV1 is deprecated on v30+. Use client.analytics instead.\n","output_type":"stream"}],"execution_count":33},{"cell_type":"code","source":"books_schema = {\n    'name': 'books',\n    'fields': [\n        {'name': 'title', 'type': 'string'},\n        {'name': 'authors', 'type': 'string[]', 'facet': True},\n        {'name': 'publication_year', 'type': 'int32', 'facet': True},\n        {'name': 'ratings_count', 'type': 'int32'},\n        {'name': 'average_rating', 'type': 'float'}\n     ],\n    'default_sorting_field': 'ratings_count'\n}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-27T11:46:51.920170Z","iopub.execute_input":"2025-12-27T11:46:51.920521Z","iopub.status.idle":"2025-12-27T11:46:51.926581Z","shell.execute_reply.started":"2025-12-27T11:46:51.920493Z","shell.execute_reply":"2025-12-27T11:46:51.925400Z"}},"outputs":[],"execution_count":31},{"cell_type":"code","source":"client.collections.create(books_schema)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"with open(\"/kaggle/input/books-data/books.jsonl\",'r',encoding='utf-8') as f:\n    data = f.read()\n    client.collections['books'].documents.import_(data)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-27T11:52:54.205552Z","iopub.execute_input":"2025-12-27T11:52:54.206637Z","iopub.status.idle":"2025-12-27T11:52:57.964047Z","shell.execute_reply.started":"2025-12-27T11:52:54.206558Z","shell.execute_reply":"2025-12-27T11:52:57.963031Z"}},"outputs":[{"name":"stderr","text":"WARNING:typesense:Deprecation warning: Overrides is deprecated on v30+. Use client.curation_sets instead.\nWARNING:typesense:Deprecation warning: The synonyms API (collections/{collection}/synonyms) is deprecated is removed on v30+. Use synonym sets (synonym_sets) instead.\n","output_type":"stream"}],"execution_count":36},{"cell_type":"code","source":"search_parameters={\n    'q':\"harry potter\",\n    'query_by': \"title, authors\",\n    \"filter_by\":\"publication_year:<1998\",\n    \"sort_by\": \"ratings_count:desc\",\n}\nclient.collections['books'].documents.search(search_parameters)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-27T11:58:03.454585Z","iopub.execute_input":"2025-12-27T11:58:03.455001Z","iopub.status.idle":"2025-12-27T11:58:03.707934Z","shell.execute_reply.started":"2025-12-27T11:58:03.454962Z","shell.execute_reply":"2025-12-27T11:58:03.706893Z"}},"outputs":[{"execution_count":41,"output_type":"execute_result","data":{"text/plain":"{'facet_counts': [],\n 'found': 1,\n 'hits': [{'document': {'authors': ['J.K. Rowling', ' Mary GrandPré'],\n    'average_rating': 4.44,\n    'id': '2',\n    'image_url': 'https://images.gr-assets.com/books/1474154022m/3.jpg',\n    'publication_year': 1997,\n    'ratings_count': 4602479,\n    'title': \"Harry Potter and the Philosopher's Stone\"},\n   'highlight': {'title': {'matched_tokens': ['Harry', 'Potter'],\n     'snippet': \"<mark>Harry</mark> <mark>Potter</mark> and the Philosopher's Stone\"}},\n   'highlights': [{'field': 'title',\n     'matched_tokens': ['Harry', 'Potter'],\n     'snippet': \"<mark>Harry</mark> <mark>Potter</mark> and the Philosopher's Stone\"}],\n   'text_match': 1157451471441100921,\n   'text_match_info': {'best_field_score': '2211897868288',\n    'best_field_weight': 15,\n    'fields_matched': 1,\n    'num_tokens_dropped': 0,\n    'score': '1157451471441100921',\n    'tokens_matched': 2,\n    'typo_prefix_score': 0}}],\n 'out_of': 9979,\n 'page': 1,\n 'request_params': {'collection_name': 'books',\n  'first_q': 'harry potter',\n  'per_page': 10,\n  'q': 'harry potter'},\n 'search_cutoff': False,\n 'search_time_ms': 2}"},"metadata":{}}],"execution_count":41},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}